{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyquery import PyQuery as pq\n",
    "import requests\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eq_df = pd.read_csv('tempdata/earthquakes_catalog.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Add column for year\\nyears = []\\nfor time in eq_df['origintime']:\\n    year = int(str.split(time, '-')[0])\\n    years.append(year)\\n    #index = time.key\\nyear_column = pd.Series(years, index=eq_df.index)\\neq_df['year'] = year_column\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Add column for year\n",
    "years = []\n",
    "for time in eq_df['origintime']:\n",
    "    year = int(str.split(time, '-')[0])\n",
    "    years.append(year)\n",
    "    #index = time.key\n",
    "year_column = pd.Series(years, index=eq_df.index)\n",
    "eq_df['year'] = year_column\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>origintime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>county</th>\n",
       "      <th>origin_src</th>\n",
       "      <th>prefmag</th>\n",
       "      <th>pmag_type</th>\n",
       "      <th>pmag_src</th>\n",
       "      <th>m3hz_ogs</th>\n",
       "      <th>md_ogs</th>\n",
       "      <th>geom</th>\n",
       "      <th>year_float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>1980-01-05 07:11:31.21</td>\n",
       "      <td>35.586</td>\n",
       "      <td>-97.894</td>\n",
       "      <td>5</td>\n",
       "      <td>CANADIAN</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.9</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0101000020E6100000F0A7C64B377958C05EBA490C02CB...</td>\n",
       "      <td>1980.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>1980-01-12 07:12:56.45</td>\n",
       "      <td>36.453</td>\n",
       "      <td>-97.642</td>\n",
       "      <td>5</td>\n",
       "      <td>GARFIELD</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.7</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0101000020E61000000C022B87166958C0448B6CE7FB39...</td>\n",
       "      <td>1980.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>257</td>\n",
       "      <td>1980-02-03 00:46:30.05</td>\n",
       "      <td>33.994</td>\n",
       "      <td>-97.463</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.2</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0101000020E61000001283C0CAA15D58C0AC1C5A643BFF...</td>\n",
       "      <td>1980.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>1980-02-05 04:32:35.45</td>\n",
       "      <td>34.046</td>\n",
       "      <td>-97.451</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.1</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0101000020E6100000BE9F1A2FDD5C58C0D9CEF753E305...</td>\n",
       "      <td>1980.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>259</td>\n",
       "      <td>1980-03-09 03:57:10.56</td>\n",
       "      <td>35.100</td>\n",
       "      <td>-95.100</td>\n",
       "      <td>5</td>\n",
       "      <td>HASKELL</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.2</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0101000020E61000006666666666C657C0CDCCCCCCCC8C...</td>\n",
       "      <td>1980.188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   id              origintime  latitude  longitude  depth    county origin_src  prefmag pmag_type pmag_src  m3hz_ogs  md_ogs                                               geom  year_float\n",
       "0           0  255  1980-01-05 07:11:31.21    35.586    -97.894      5  CANADIAN        OGS      1.9      M3Hz      OGS       1.9     1.7  0101000020E6100000F0A7C64B377958C05EBA490C02CB...    1980.130\n",
       "1           1  256  1980-01-12 07:12:56.45    36.453    -97.642      5  GARFIELD        OGS      1.7      M3Hz      OGS       1.7     1.4  0101000020E61000000C022B87166958C0448B6CE7FB39...    1980.320\n",
       "2           2  257  1980-02-03 00:46:30.05    33.994    -97.463      5      LOVE        OGS      2.2      M3Hz      OGS       2.2     2.0  0101000020E61000001283C0CAA15D58C0AC1C5A643BFF...    1980.920\n",
       "3           3  258  1980-02-05 04:32:35.45    34.046    -97.451      5      LOVE        OGS      2.1      M3Hz      OGS       2.1     1.9  0101000020E6100000BE9F1A2FDD5C58C0D9CEF753E305...    1980.980\n",
       "4           4  259  1980-03-09 03:57:10.56    35.100    -95.100      5   HASKELL        OGS      1.2      M3Hz      OGS       1.2     1.4  0101000020E61000006666666666C657C0CDCCCCCCCC8C...    1980.188"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous things to add to final notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.1 Additional Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "#import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.2 Poisson Process Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.2.1 No Recent Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to create list of interarrival times in hours from df \n",
    "#1\n",
    "def get_hours_between(df):\n",
    "    dates=[]\n",
    "    origintimes = df.origintime.values\n",
    "    for date in origintimes:\n",
    "        year, month, day = date.split('-')\n",
    "        day, hour = day.split(' ')\n",
    "        hour, minute, second = hour.split(':')\n",
    "        if len(second.split('.'))==2:\n",
    "            second, microsecond = second.split('.')\n",
    "        elif len(second.split('.'))==1:\n",
    "            microsecond=0\n",
    "        dates.append(datetime.datetime(int(year), int(month), int(day), int(hour), int(minute), \n",
    "                                       int(second), int(microsecond)))\n",
    "    dates=sorted(dates)\n",
    "    deltas=[]\n",
    "    for i in range(1,len(dates)):\n",
    "        delta = dates[i] - dates[i-1]\n",
    "        delta = delta.total_seconds()/3600\n",
    "        deltas.append(delta)\n",
    "    deltas = np.array(deltas)\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.2.2 Recent Changes, Need to add to Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2\n",
    "#fit and plot exponential to data\n",
    "#k is manual assessment of number of parameters\n",
    "def fit_expo(deltas, bins=100, xmax=100, ymax=0.02, k=1., force_lambd=None, plot=True):\n",
    "    #Use Maxmimum Likelihood Estimator to get exponential fit\n",
    "    expo_fit = sp.stats.expon.fit(deltas, floc=0)\n",
    "    \n",
    "    #Calculate Summary Statistics\n",
    "    k=float(k)\n",
    "    mean = np.mean(deltas) #sample mean\n",
    "    if pd.isnull(force_lambd):\n",
    "        lambd = expo_fit[1] #fitted mean\n",
    "    else:\n",
    "        lambd=force_lambd\n",
    "    n = float(len(deltas))\n",
    "    ks_d, ks_pval=sp.stats.kstest(deltas, 'expon', alternative='two-sided')\n",
    "    ppstats = sp.stats.probplot(deltas, dist='expon')\n",
    "    r = ppstats[1][2]\n",
    "    r2 = r**2\n",
    "    log_lik = n*np.log(lambd) - lambd*np.sum(deltas)\n",
    "    aic = 2*k - 2*log_lik\n",
    "    ssr = np.sum((deltas-lambd)**2)\n",
    "    aic2 = n*np.log(ssr/n) + 2*k\n",
    "    aic_c = aic + float(((2*k)*(k+1))/(n-k-1))\n",
    "    mse = np.mean((deltas-lambd)**2)\n",
    "    ad = sp.stats.anderson(deltas, dist='expon')\n",
    "    ad_stat = ad[0]\n",
    "    ad_critical_value = ad[1][2]\n",
    "\n",
    "    \n",
    "    if plot==True:\n",
    "        #Overlay fitted exponential over histogram\n",
    "        plt.hist(deltas, bins=bins, normed=True)\n",
    "        x = np.arange(0,xmax,0.01)\n",
    "        y = sp.stats.expon.pdf(x, scale=lambd)\n",
    "        plt.plot(x,y)\n",
    "        plt.xlim([0,xmax])\n",
    "        plt.ylim([0,ymax])\n",
    "\n",
    "        #QQ Plot for fit to exponential\n",
    "        sm.qqplot(deltas, dist='expon', fit=True, line='45')\n",
    "        plt.show()\n",
    "    \n",
    "    #Print Summary Statistics\n",
    "    print \"Summary Statistics for Distributional Fit\"\n",
    "    print \"lambda = \" + str(lambd)\n",
    "    print \"mean(data) = \" + str(mean)\n",
    "    print \"sample size = \" + str(n)\n",
    "    print \"AIC = \" + str(aic) + \"??\" \n",
    "    print \"AICc = \" + str(aic_c) + \"??\"\n",
    "    print \"ssr= \" + str(ssr) \n",
    "    print \"AIC2 =\" + str(aic2) + \"??\"\n",
    "    print \"Summary Statistics for Predicton\"\n",
    "    print \"MSE = \" + str(mse)\n",
    "    print \"####Not Updated for Comparing Models#####\"\n",
    "    print \"Kolmogorov-Smirnov Test Statistic D=\" + str(ks_d)\n",
    "    print \"Kolmogorov-Smirnov Test p-value=\" + str(ks_pval)\n",
    "    print \"QQ R^2 = \" + str(r2)\n",
    "    print \"AD Stat = \" + str(ad_stat)\n",
    "    print \"AD Critical Value = \" + str(ad_critical_value)\n",
    "    return(lambd, mean, n, ks_d, ks_pval, r2, aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "#get interarrival times for whole df\n",
    "def show_expo_fit(df, bins=40, xmax=10000, ymax=0.001, k=1., force_lambd=None, plot=True):\n",
    "    deltas = get_hours_between(df)\n",
    "    fit = fit_expo(deltas, bins=bins, xmax=xmax, ymax=ymax, k=k, force_lambd=force_lambd, plot=plot)\n",
    "    lambd = fit[0]\n",
    "    return lambd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Chi-Squared Goodness of Fit Test http://www.itl.nist.gov/div898/handbook/eda/section3/eda35f.htm\n",
    "\n",
    "Note: Could also fit to Poisson\n",
    "\n",
    "Note: Look into \"fit\" algorithm in scipy, statsmodels\n",
    "\n",
    "Note: Is this the standard plot for showing distributional fit? \n",
    "\n",
    "Note: Need to look into understanding QQ Plots and Probability Plots\n",
    "\n",
    "Use AIC for comparing distributional fit.\n",
    "\n",
    "    *Starting Point: Given taht this is the correct distribution, what is the log-likelihood of the data?\n",
    "    \n",
    "    *if the number of data points is small, then some correction is often necessary (see AICc, below).\n",
    "    \n",
    "    *\\mathrm{AIC} = 2k - 2\\ln(L)\n",
    "    *Important websites: http://www.easydatascience.com\n",
    "    *http://stats.stackexchange.com/questions/31768/is-it-okay-to-compare-fitted-distributions-with-the-aic\n",
    "\n",
    "Look into nonparametric methods for simulating the distribution here.\n",
    "\n",
    "Look into this further: http://www.geos.ed.ac.uk/homes/abell5/Modelcode.html\n",
    "\n",
    "Power Law as a Model for Earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Baseline fit is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Distributional Fit\n",
      "lambda = 16.6940496181\n",
      "mean(data) = 16.5797702164\n",
      "sample size = 18990.0\n",
      "AIC = 10405323.8944??\n",
      "AICc = 10405323.8947??\n",
      "ssr= 139442083.663\n",
      "AIC2 =169041.334947??\n",
      "Summary Statistics for Predicton\n",
      "MSE = 7342.92173052\n",
      "####Not Updated for Comparing Models#####\n",
      "Kolmogorov-Smirnov Test Statistic D=0.243090380217\n",
      "Kolmogorov-Smirnov Test p-value=0.0\n",
      "QQ R^2 = 0.448214169706\n",
      "AD Stat = inf\n",
      "AD Critical Value = 1.341\n"
     ]
    }
   ],
   "source": [
    "lambd1 = show_expo_fit(eq_df, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 Splitting at 2010 is better: pre-2010 looks like Poisson Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how well the previous model predicted the data before 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Distributional Fit\n",
      "lambda = 16.6940496181\n",
      "mean(data) = 156.831564075\n",
      "sample size = 1676.0\n",
      "AIC = 8766617.85873??\n",
      "AICc = 8766617.86112??\n",
      "ssr= 135454137.015\n",
      "AIC2 =18940.7637778??\n",
      "Summary Statistics for Predicton\n",
      "MSE = 80819.8908201\n",
      "####Not Updated for Comparing Models#####\n",
      "Kolmogorov-Smirnov Test Statistic D=0.702367579658\n",
      "Kolmogorov-Smirnov Test p-value=0.0\n",
      "QQ R^2 = 0.959413948951\n",
      "AD Stat = 556.03939785\n",
      "AD Critical Value = 1.341\n"
     ]
    }
   ],
   "source": [
    "lambd2 = show_expo_fit(eq_df[eq_df.year_float<2010], force_lambd=lambd1, plot=False, k=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the fit when we do split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Distributional Fit\n",
      "lambda = 156.831519794\n",
      "mean(data) = 156.831564075\n",
      "sample size = 1676.0\n",
      "AIC = 82429295.3557??\n",
      "AICc = 82429295.3628??\n",
      "ssr= 102539972.537\n",
      "AIC2 =18476.1982069??\n",
      "Summary Statistics for Predicton\n",
      "MSE = 61181.3678621\n",
      "####Not Updated for Comparing Models#####\n",
      "Kolmogorov-Smirnov Test Statistic D=0.702367579658\n",
      "Kolmogorov-Smirnov Test p-value=0.0\n",
      "QQ R^2 = 0.959413948951\n",
      "AD Stat = 556.03939785\n",
      "AD Critical Value = 1.341\n"
     ]
    }
   ],
   "source": [
    "lambd3 = show_expo_fit(eq_df[eq_df.year_float<2010], plot=False, k=2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exponential Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'families'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-4b0fc6e32a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mexponential_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamilies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamilies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mexp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexponential_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mexp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'families'"
     ]
    }
   ],
   "source": [
    "#Exponential Regression\n",
    "x = np.arange(1,100,1)\n",
    "y = np.random.poisson(x)\n",
    "df = pd.DataFrame({'x': x, 'y': y}, index=range(1,100))\n",
    "\n",
    "exponential_model = sm2.GLM(y,x, sm.families.family.Poisson(sm.genmod.families.links.identity))\n",
    "exp_model = exponential_model.fit()\n",
    "print exp_model.summary()\n",
    "plt.plot(x,y)\n",
    "\n",
    "#ols_model = sm.ols(formula = 'y~x', data = df).fit()\n",
    "#print ols_model.summary()\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[statsmodels.genmod.families.links.log,\n",
       " statsmodels.genmod.families.links.identity,\n",
       " statsmodels.genmod.families.links.sqrt]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.families.family.Poisson.links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
