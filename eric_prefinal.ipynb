{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyquery import PyQuery as pq\n",
    "import requests\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eq_df = pd.read_csv('tempdata/since_1980.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add column for year\n",
    "years = []\n",
    "for time in eq_df['origintime']:\n",
    "    year = int(str.split(time, '-')[0])\n",
    "    years.append(year)\n",
    "    #index = time.key\n",
    "year_column = pd.Series(years, index=eq_df.index)\n",
    "eq_df['year'] = year_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>origintime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>err_lon</th>\n",
       "      <th>err_lat</th>\n",
       "      <th>err_depth</th>\n",
       "      <th>err_origintime</th>\n",
       "      <th>county</th>\n",
       "      <th>origin_src</th>\n",
       "      <th>prefmag</th>\n",
       "      <th>pmag_type</th>\n",
       "      <th>pmag_src</th>\n",
       "      <th>mw</th>\n",
       "      <th>mw_src</th>\n",
       "      <th>mblg_ogs</th>\n",
       "      <th>mblg_usgs</th>\n",
       "      <th>ml_ogs</th>\n",
       "      <th>m3hz_ogs</th>\n",
       "      <th>md_ogs</th>\n",
       "      <th>mb</th>\n",
       "      <th>ms</th>\n",
       "      <th>mfa</th>\n",
       "      <th>max_mmi</th>\n",
       "      <th>reafile</th>\n",
       "      <th>reamtime</th>\n",
       "      <th>geom</th>\n",
       "      <th>pdlid</th>\n",
       "      <th>mw_ogs</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>1980-01-05 07:11:31.21</td>\n",
       "      <td>35.586</td>\n",
       "      <td>-97.894</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANADIAN</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.9</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E6100000F0A7C64B377958C05EBA490C02CB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>1980-01-12 07:12:56.45</td>\n",
       "      <td>36.453</td>\n",
       "      <td>-97.642</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GARFIELD</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.7</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000000C022B87166958C0448B6CE7FB39...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>257</td>\n",
       "      <td>1980-02-03 00:46:30.05</td>\n",
       "      <td>33.994</td>\n",
       "      <td>-97.463</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOVE</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.2</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000001283C0CAA15D58C0AC1C5A643BFF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>1980-02-05 04:32:35.45</td>\n",
       "      <td>34.046</td>\n",
       "      <td>-97.451</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOVE</td>\n",
       "      <td>OGS</td>\n",
       "      <td>2.1</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E6100000BE9F1A2FDD5C58C0D9CEF753E305...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>259</td>\n",
       "      <td>1980-03-09 03:57:10.56</td>\n",
       "      <td>35.100</td>\n",
       "      <td>-95.100</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HASKELL</td>\n",
       "      <td>OGS</td>\n",
       "      <td>1.2</td>\n",
       "      <td>M3Hz</td>\n",
       "      <td>OGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101000020E61000006666666666C657C0CDCCCCCCCC8C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   id              origintime  latitude  longitude  depth  err_lon  err_lat  err_depth  err_origintime    county origin_src  prefmag pmag_type pmag_src  mw mw_src  mblg_ogs  mblg_usgs  ml_ogs  m3hz_ogs  md_ogs  mb  ms  mfa  max_mmi reafile reamtime                                               geom  pdlid  mw_ogs  year\n",
       "0           0  255  1980-01-05 07:11:31.21    35.586    -97.894      5      NaN      NaN        NaN             NaN  CANADIAN        OGS      1.9      M3Hz      OGS NaN    NaN       1.6        NaN     NaN       1.9     1.7 NaN NaN  NaN      NaN     NaN      NaN  0101000020E6100000F0A7C64B377958C05EBA490C02CB...    NaN     NaN  1980\n",
       "1           1  256  1980-01-12 07:12:56.45    36.453    -97.642      5      NaN      NaN        NaN             NaN  GARFIELD        OGS      1.7      M3Hz      OGS NaN    NaN       NaN        NaN     NaN       1.7     1.4 NaN NaN  NaN      NaN     NaN      NaN  0101000020E61000000C022B87166958C0448B6CE7FB39...    NaN     NaN  1980\n",
       "2           2  257  1980-02-03 00:46:30.05    33.994    -97.463      5      NaN      NaN        NaN             NaN      LOVE        OGS      2.2      M3Hz      OGS NaN    NaN       1.9        NaN     NaN       2.2     2.0 NaN NaN  NaN      NaN     NaN      NaN  0101000020E61000001283C0CAA15D58C0AC1C5A643BFF...    NaN     NaN  1980\n",
       "3           3  258  1980-02-05 04:32:35.45    34.046    -97.451      5      NaN      NaN        NaN             NaN      LOVE        OGS      2.1      M3Hz      OGS NaN    NaN       2.3        NaN     NaN       2.1     1.9 NaN NaN  NaN        3     NaN      NaN  0101000020E6100000BE9F1A2FDD5C58C0D9CEF753E305...    NaN     NaN  1980\n",
       "4           4  259  1980-03-09 03:57:10.56    35.100    -95.100      5      NaN      NaN        NaN             NaN   HASKELL        OGS      1.2      M3Hz      OGS NaN    NaN       1.4        NaN     NaN       1.2     1.4 NaN NaN  NaN      NaN     NaN      NaN  0101000020E61000006666666666C657C0CDCCCCCCCC8C...    NaN     NaN  1980"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous things to add to final notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.1 Additional Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.2 Poisson Process Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.2.1 No Recent Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to create list of interarrival times in hours from df \n",
    "#1\n",
    "def get_hours_between(df):\n",
    "    dates=[]\n",
    "    origintimes = df.origintime.values\n",
    "    for date in origintimes:\n",
    "        year, month, day = date.split('-')\n",
    "        day, hour = day.split(' ')\n",
    "        hour, minute, second = hour.split(':')\n",
    "        if len(second.split('.'))==2:\n",
    "            second, microsecond = second.split('.')\n",
    "        elif len(second.split('.'))==1:\n",
    "            microsecond=0\n",
    "        dates.append(datetime.datetime(int(year), int(month), int(day), int(hour), int(minute), \n",
    "                                       int(second), int(microsecond)))\n",
    "    dates=sorted(dates)\n",
    "    deltas=[]\n",
    "    for i in range(1,len(dates)):\n",
    "        delta = dates[i] - dates[i-1]\n",
    "        delta = delta.total_seconds()/3600\n",
    "        deltas.append(delta)\n",
    "    deltas = np.array(deltas)\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0.2.2 Recent Changes, Need to add to Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2\n",
    "#fit and plot exponential to data\n",
    "#k is manual assessment of number of parameters\n",
    "def fit_expo(deltas, bins=100, xmax=100, ymax=0.02, k=1., force_lambd=None, plot=True):\n",
    "    #Use Maxmimum Likelihood Estimator to get exponential fit\n",
    "    expo_fit = sp.stats.expon.fit(deltas, floc=0)\n",
    "    \n",
    "    #Calculate Summary Statistics\n",
    "    k=float(k)\n",
    "    mean = np.mean(deltas) #sample mean\n",
    "    if pd.isnull(force_lambd):\n",
    "        lambd = expo_fit[1] #fitted mean\n",
    "    else:\n",
    "        lambd=force_lambd\n",
    "    n = float(len(deltas))\n",
    "    ks_d, ks_pval=sp.stats.kstest(deltas, 'expon', alternative='two-sided')\n",
    "    ppstats = sp.stats.probplot(deltas, dist='expon')\n",
    "    r = ppstats[1][2]\n",
    "    r2 = r**2\n",
    "    log_lik = n*np.log(lambd) - lambd*np.sum(deltas)\n",
    "    aic = 2*k - 2*log_lik\n",
    "    ssr = np.sum((deltas-lambd)**2)\n",
    "    aic2 = n*np.log(ssr/n) + 2*k\n",
    "    aic_c = aic + float(((2*k)*(k+1))/(n-k-1))\n",
    "    mse = np.mean((deltas-lambd)**2)\n",
    "    \n",
    "    if plot==True:\n",
    "        #Overlay fitted exponential over histogram\n",
    "        plt.hist(deltas, bins=bins, normed=True)\n",
    "        x = np.arange(0,xmax,0.01)\n",
    "        y = sp.stats.expon.pdf(x, scale=lambd)\n",
    "        plt.plot(x,y)\n",
    "        plt.xlim([0,xmax])\n",
    "        plt.ylim([0,ymax])\n",
    "\n",
    "        #QQ Plot for fit to exponential\n",
    "        sm.qqplot(deltas, dist='expon', fit=True, line='45')\n",
    "        plt.show()\n",
    "    \n",
    "    #Print Summary Statistics\n",
    "    print \"Summary Statistics for Distributional Fit\"\n",
    "    print \"lambda = \" + str(lambd)\n",
    "    print \"mean(data) = \" + str(mean)\n",
    "    print \"sample size = \" + str(n)\n",
    "    print \"Kolmogorov-Smirnov Test Statistic D=\" + str(ks_d)\n",
    "    print \"Kolmogorov-Smirnov Test p-value=\" + str(ks_pval)\n",
    "    print \"QQ R^2 = \" + str(r2)\n",
    "    print \"AIC = \" + str(aic) + \"??\" \n",
    "    print \"AICc = \" + str(aic_c) + \"??\"\n",
    "    print \"ssr= \" + str(ssr) \n",
    "    print \"AIC2 =\" + str(aic2) + \"??\"\n",
    "    print \"Summary Statistics for Prediciton\"\n",
    "    print \"MSE = \" + str(mse)\n",
    "    return(lambd, mean, n, ks_d, ks_pval, r2, aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESTING\n",
    "pd.notnull(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "#get interarrival times for whole df\n",
    "def show_expo_fit(df, bins=40, xmax=10000, ymax=0.001, force_lambd=None, plot=True):\n",
    "    deltas = get_hours_between(df)\n",
    "    fit = fit_expo(deltas, bins=bins, xmax=xmax, ymax=ymax, force_lambd=force_lambd, plot=plot)\n",
    "    lambd = fit[0]\n",
    "    return lambd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Chi-Squared Goodness of Fit Test http://www.itl.nist.gov/div898/handbook/eda/section3/eda35f.htm\n",
    "\n",
    "Note: Could also fit to Poisson\n",
    "\n",
    "Note: Look into \"fit\" algorithm in scipy, statsmodels\n",
    "\n",
    "Note: Is this the standard plot for showing distributional fit? \n",
    "\n",
    "Note: Need to look into understanding QQ Plots and Probability Plots\n",
    "\n",
    "Use AIC for comparing distributional fit.\n",
    "\n",
    "    *Starting Point: Given taht this is the correct distribution, what is the log-likelihood of the data?\n",
    "    \n",
    "    *if the number of data points is small, then some correction is often necessary (see AICc, below).\n",
    "    \n",
    "    *\\mathrm{AIC} = 2k - 2\\ln(L)\n",
    "    *Important websites: http://www.easydatascience.com\n",
    "    *http://stats.stackexchange.com/questions/31768/is-it-okay-to-compare-fitted-distributions-with-the-aic\n",
    "\n",
    "Look into nonparametric methods for simulating the distribution here.\n",
    "\n",
    "Look into this further: http://www.geos.ed.ac.uk/homes/abell5/Modelcode.html\n",
    "\n",
    "Power Law as a Model for Earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Baseline fit is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Distributional Fit\n",
      "lambda = 16.7381849082\n",
      "mean(data) = 16.6232702927\n",
      "sample size = 18934.0\n",
      "Kolmogorov-Smirnov Test Statistic D=0.243072619456\n",
      "Kolmogorov-Smirnov Test p-value=0.0\n",
      "QQ R^2 = 0.448843873171\n",
      "AIC = 10429821.624??\n",
      "AICc = 10429821.6242??\n",
      "ssr= 139430426.204\n",
      "AIC2 =168597.185777??\n",
      "Summary Statistics for Prediciton\n",
      "MSE = 7364.01057216\n"
     ]
    }
   ],
   "source": [
    "lambd1 = show_expo_fit(eq_df, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 Splitting at 2010 is better: pre-2010 looks like Poisson Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how well the previous model predicted the data before 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Distributional Fit\n",
      "lambda = 16.7381849082\n",
      "mean(data) = 156.831564075\n",
      "sample size = 1676.0\n",
      "Kolmogorov-Smirnov Test Statistic D=0.702367579658\n",
      "Kolmogorov-Smirnov Test p-value=0.0\n",
      "QQ R^2 = 0.959413948951\n",
      "AIC = 8789810.90413??\n",
      "AICc = 8789810.90652??\n",
      "ssr= 135433408.126\n",
      "AIC2 =18940.5072757??\n",
      "Summary Statistics for Prediciton\n",
      "MSE = 80807.5227483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.738184908201816"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_expo_fit(eq_df[eq_df.year<2010], force_lambd=lambd1, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the fit when we do split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Distributional Fit\n",
      "lambda = 156.831519794\n",
      "mean(data) = 156.831564075\n",
      "sample size = 1676.0\n",
      "Kolmogorov-Smirnov Test Statistic D=0.702367579658\n",
      "Kolmogorov-Smirnov Test p-value=0.0\n",
      "QQ R^2 = 0.959413948951\n",
      "AIC = 82429293.3557??\n",
      "AICc = 82429293.3581??\n",
      "ssr= 102539972.537\n",
      "AIC2 =18474.1982069??\n",
      "Summary Statistics for Prediciton\n",
      "MSE = 61181.3678621\n"
     ]
    }
   ],
   "source": [
    "lambd2 = show_expo_fit(eq_df[eq_df.year<2010], plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exponential Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-3a476b1942b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#exponential_model = sm.GLM(y,x, sm.families.Poisson(sm.genmod.families.links.identity))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    213\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         return _arrays_to_mgr(arrays, data_names, index, columns,\n\u001b[0;32m--> 341\u001b[0;31m                               dtype=dtype)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     def _init_ndarray(self, values, index, columns, dtype=None,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   4801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4802\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4803\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4805\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   5110\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5111\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[0;32m-> 5112\u001b[0;31m                                 raise_cast_failure=False)\n\u001b[0m\u001b[1;32m   5113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5114\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2718\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2720\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data must be 1-dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2722\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "#Exponential Regression\n",
    "x = np.arange(1,100,1)\n",
    "x = sm.add_constant(x)\n",
    "y = np.random.poisson(x)\n",
    "df = pd.DataFrame({'x': x, 'y': y}, index=)\n",
    "\n",
    "#exponential_model = sm.GLM(y,x, sm.families.Poisson(sm.genmod.families.links.identity))\n",
    "#exp_model = exponential_model.fit()\n",
    "#print exp_model.summary()\n",
    "#plt.plot(x,y)\n",
    "\n",
    "ols_model = sm.ols(formula = 'y ~ x', data = df).fit()\n",
    "print ols_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[statsmodels.genmod.families.links.log,\n",
       " statsmodels.genmod.families.links.identity,\n",
       " statsmodels.genmod.families.links.sqrt]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.families.family.Poisson.links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
